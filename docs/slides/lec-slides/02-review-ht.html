<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Inference Review</title>
    <meta charset="utf-8" />
    <meta name="author" content="Prof. Maria Tackett" />
    <link href="libs/countdown/countdown.css" rel="stylesheet" />
    <script src="libs/countdown/countdown.js"></script>
    <link rel="stylesheet" href="sta210-slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Inference Review
## Hypothesis Testing
### Prof. Maria Tackett
### 01.15.19

---






class: middle, center

### [Click for PDF of slides](02-review-ht.pdf)

---

### Announcements

- Complete [surveys and consent form](https://www2.stat.duke.edu/courses/Spring20/sta210.001/misc/jan8.html) by Wed at 11:59p

- [Reading for next Wednesday](https://www2.stat.duke.edu/courses/Spring20/sta210.001/reading/reading-02.html)

- Labs start tomorrow! 

- No class Monday - Martin Luther King, Jr. Holiday

- Find more info about statistics related events on [Sakai](https://sakai.duke.edu)

---

## Today's Agenda

- Calculating &amp; interpreting hypothesis tests

- Connecting hypothesis tests and confidence intervals

---

### *Sesame Street*

- *Sesame Street* is a television series designed to teach children ages 3-5 basic education skills such as reading (e.g. the alphabet) and math (e.g. counting)

- Today we are going to analyze data from an [study conducted by the Educational Testing Service](http://files.eric.ed.gov/fulltext/ED122799.pdf) in the early 1970s to test the  effectiveness of the program. 

&lt;img src="img/01/sesame_street.jpg" width="50%" style="display: block; margin: auto;" /&gt;
---

### *Sesame Street* study

- Children from 6 locations around the United States (including Durham!) participated in the 26-week study. The children were split into two groups (`treatment`):
      + **Group 1**: Those who were encouraged to watch the show (assume watched regularly)
      + **Group 2**: Those who didn't get encouragement to watch the show (assume didn't watch regularly)

- Each child was given a test before and after the study to measure their knowledge of basic math, reading, etc.

- We will focus on the change in reading (identifying letters) scores (`change`)
&lt;br&gt;&lt;br&gt;

&lt;small&gt;
[Sesame Street Data - Full Description](http://www2.stat.duke.edu/~jerry/sta210/sesamelab.html) 
Original Study: *Ann Bogatz, Gerry &amp; Ball, Samuel. (1971). The Second Year of Sesame Street: A Continuing Evaluation. Volume 1. vols. 1 &amp; 2.*
&lt;/small&gt;

---

### Let's look at the data

`sesame_street.csv` is available in the datasets repo on GitHub.




```r
sesame_street %&gt;%
  slice(1:10)
```

```
## # A tibble: 10 x 4
##    treatment      prelet postlet change
##    &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;
##  1 Encouraged         23      30      7
##  2 Encouraged         26      37     11
##  3 Not Encouraged     14      46     32
##  4 Not Encouraged     11      14      3
##  5 Not Encouraged     47      63     16
##  6 Not Encouraged     26      36     10
##  7 Not Encouraged     12      45     33
##  8 Encouraged         48      47     -1
##  9 Encouraged         44      50      6
## 10 Encouraged         38      52     14
```

---

### Exploratory Data Analysis - Univariate

&lt;small&gt;

```r
ggplot(data = sesame_street, mapping = aes(x = change)) +
  geom_histogram(fill = "steelblue", color = "black") +
  labs(x = "Change in Reading Score (Post - Pre)" , 
       title = "Distribution of the Change in Reading Scores")
```

&lt;img src="02-review-ht_files/figure-html/unnamed-chunk-5-1.png" style="display: block; margin: auto;" /&gt;
&lt;/small&gt;

---

### Exploratory Data Analysis - Univariate

- Calculate summary statistics for `change`
&lt;small&gt;

```r
sesame_street %&gt;%
  summarise(n = n(), min = min(change), median = median(change), max = max(change), 
            IQR = IQR(change), 
            mean = mean(change), std_dev = sd(change))
```

```
## # A tibble: 1 x 7
##       n   min median   max   IQR  mean std_dev
##   &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
## 1   240   -22      9    41    15  10.8    11.2
```
&lt;/small&gt;

---

### 95% CI for mean change in reading score

The 95% confidence interval for the mean change in reading score is 

`$$\mathbf{[9.384, 12.224]}$$`


.question[

- Interpret the interval at http://bit.ly/sta210-sp20-CI-2

- Use **NetId@duke.edu** for your email address.

- You are welcome (and encouraged!) to discuss these questions with 1 - 2 people around you, but **each person** must submit a response.
]


<div class="countdown" id="timer_5e1e3b7d" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">03</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---

## Hypothesis Tests

- Question we want to answer: 

.center[
*Are the data consistent or inconsistent with the specified hypothesis?*
]
&lt;br&gt;

- To answer that question, we will determine

.center[
*Given the collected data, is there evidence &lt;u&gt;against&lt;/u&gt; a specified hypothesis about the corresponding parameter?*
]
--

.instructions[
Is the averagee improvement in reading scores significantly greater for children who regularly watch *Sesame Street* than the change for those who don't?
]


---

## Hypotheses

- &lt;font class="vocab"&gt;Null hypothesis, `\(H_0\)`&lt;/font&gt;: This is the baseline hypothesis, i.e. the "there is nothing going on" hypothesis. 
    - There is no difference in the reading development between children who watch *Sesame Street* regularly and those who don't.
&lt;br&gt;&lt;br&gt;

- &lt;font class = "vocab"&gt;Alternative hypothesis, `\(H_a\)`&lt;/font&gt;: This is typically what you want to show, i.e. the "there is something going on" hypothesis 
    - Children who regularly watch *Sesame Street* have significantly greater improvement in reading scores compared to those who don't

---

## Outline of a Hypothesis Test

- Identify the parameter of interest. 

- Identify a null hypothesis, `\(H_0\)`, that represents the baseline

- Set an alternative hypothesis, `\(H_a\)`, that represents the research question, i.e. what you're testing

- Conduct a hypothesis test under the assumption that the null hypothesis is true and calculate a p-value
    - The &lt;font class = "vocab"&gt;p-value&lt;/font&gt; is the probability of getting the observed outcome or a more extreme outcome given the null hypothesis is true

---

## Outline of a Hypothesis Test

- Assess the p-value. A small p-value means...
    
    a. The assumed (null) hypothesis is incorrect
    
    b. The assumed (null) hypothesis is correct and a rare event has occured 
    
- State a conclusion about the hypothesis based on the assessment of the p-value
--

  - Since event (b) is by definition rare, we will conclude a &lt;font color = "red"&gt;"small" p-value&lt;/font&gt; indicates that there is &lt;font color = "red"&gt;sufficient evidence to claim that the assumed hypothesis is false&lt;/font&gt;.
      - In other words, the data are not consistent with the assumed hypothesis 

--

  - When the p-value is &lt;font color = "blue"&gt; "not small"&lt;/font&gt;, we will conclude that there is &lt;font color = "blue"&gt;not sufficient evidence&lt;/font&gt; to claim the assumed hypothesis is false.

---


## *Sesame Street* Example

- **Question: ** Is the averagee improvement in reading scores significantly greater for children who regularly watch *Sesame Street* than the change for those who don't?
--

- **Baseline: ** There is no difference between the two groups
--

- **Claim: **The average improvement in reading scores for children who watch *Sesame Street* is greater than the average improvement of children who don't. We will use encouragement as a proxy for watching the show.
--

- **Hypotheses: ** 

$$
`\begin{aligned}
&amp; H_0: \mu_e - \mu_{ne} = 0\\
&amp; H_a: \mu_e - \mu_{ne} &gt; 0 
\end{aligned}`
$$
---

### Distribution of sample statistic under `\(H_0\)`

- We conduct hypothesis testing under the assumption that the null hypothesis is true, `\(H_0: \mu_e - \mu_{ne} = 0\)`

- We use sample statistics `\(\bar{x}_e\)` and `\(\bar{x}_{ne}\)` to help us understand the parameters. 

- If the null hypothesis is true, we could randomly relabel the observations as Group 1 and Group 2 and recalculate the sample statistic `\(\bar{x}_e - \bar{x}_{ne}\)`

- Let's do this relabeling about 1000 times and see what the distribution of `\(\bar{x}_e - \bar{x}_{ne}\)` looks like

---

### Simulated distribution of sample statistic under `\(H_0\)`



&lt;img src="02-review-ht_files/figure-html/unnamed-chunk-9-1.png" style="display: block; margin: auto;" /&gt;

---

In our actual data, we observed a difference of **12.5 - 7.875 = 4.625**

&lt;img src="02-review-ht_files/figure-html/unnamed-chunk-10-1.png" style="display: block; margin: auto;" /&gt;

.question[
What proportion of the 1000 observations yielded values of `\(\bar{x}_e - \bar{x}_{ne}\)` as or more extreme as the value we observed in the data?
]

---

&lt;img src="02-review-ht_files/figure-html/unnamed-chunk-11-1.png" style="display: block; margin: auto;" /&gt;

.question[
What is your conclusion about the effectiveness of *Sesame Street* in helping students improve their reading skills?
]

---

class: middle, center 

### Inference Using the Central Limit Theorem

---

## Sampling Distributions

- &lt;font class = "vocab"&gt;Sampling distribution&lt;/font&gt;: the distribution of sample statistics of random samples of size `\(n\)` taken with replacement from a population

- If we take repeated samples from a population, each sample will yield a slightly different value of the sample statistic

- We can measure the variability in these sample statistics by the &lt;font class = "vocab"&gt;standard error&lt;/font&gt;

---

## In practice...

We can't directly know what the sampling distributions looks like, because we only draw a single sample.

- The whole point of statistical inference is to deal with this issue: observe only one sample, try to make inference about the entire population

- One approach is to simulate the distributions as we did earlier, but we will now rely on theoretical results. 

--

- The &lt;font class = "vocab"&gt;Central Limit Theorem &lt;/font&gt; is a theoretical result that tells us what the sampling distribution should look like (for certain sample statistics)

- The Central Limit Theorem provides the foundation we need to conduct inference on parameters such as the mean, proportion, difference in means, and regression coefficients (coming soon!)

---

### Central Limit Theorem 

If certain conditions are met, the sampling distribution of the sample statistic will..

- be approximately Normal
- have a mean equal to the unknown population parameter
- have a standard error proportional to the inverse of the square root of the sample size.

---

## Central Limit Theorem

&lt;font class="vocab"&gt;One Sample: &lt;/font&gt;

- **Single mean:** `\(\bar{x} \sim N\left(mean = \mu, sd = \frac{\sigma}{\sqrt{n}}\right)\)`
- **Single proportion:** `\(\hat{p} \sim N\left(mean = p, sd = \sqrt{\frac{p (1-p)}{n}} \right)\)`

&lt;br&gt;

&lt;font class="vocab"&gt;Two Sample: &lt;/font&gt;

- **Difference between two means:** `\((\bar{x}_1 - \bar{x}_2) \sim N\left(mean = (\mu_1 - \mu_2), sd = \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}} \right)\)`

- **Difference between two proportions:** `\((\hat{p}_1 - \hat{p}_2) \sim N\left(mean = (p_1 - p_2), sd = \sqrt{\frac{p_1 (1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}} \right)\)`

---

### Conditions required for the CLT

- **Independence:** The sampled observations must be independent. This is difficult to check, but the following are useful guidelines:
    - the sample must be random
    - if sampling without replacement, sample size must be less than 10% of the population size
    
- **Sample size / distribution:** 
    - numerical data: The more skewed the sample (and hence the population)
    distribution, the larger samples we need. Usually n &gt; 30 is considered a 
    large enough sample for population distributions that are not extremely skewed.
    - categorical data: At least 10 successes and 10 failures.

- If comparing two populations, the groups must be independent of each other,
and all conditions should be checked for both groups.

---

## Standard Error

The &lt;font class="vocab"&gt;standard error&lt;/font&gt; is the *standard deviation* of the *sampling distribution*, calculated using sample statistics (since we don't know the population parameters like `\(\sigma\)` or `\(p\)`).

--

- **Single mean:** `\(SE = \frac{s}{\sqrt{n}}\)`

- **Difference between two means:** `\(SE = \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}\)`

- **Single proportion:** `\(SE = \sqrt{\frac{\hat{p} (1-\hat{p})}{n}}\)`

- **Difference between two proportions:** `\(SE = \sqrt{\frac{\hat{p}_1 (1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}\)`

--

.question[
How are standard error and sample size associated? What does that say about how the spread of the sampling distribution changes as `\(n\)` increases?
]

---

## Hypothesis Tests Using the CLT 

- State the null and alternative hypotheses 

--


-  Calculate the standard error of the sample statistic of interest (sample mean, sample proportion, difference between sample means, etc.)

--

- Calculate the &lt;font class = "vocab"&gt;test statistic&lt;/font&gt;, the number of standard errors the observed value is from the hypothesized null value. The appropriate test statistic is...
$$ \frac{\text{observed value} - \text{hypothesized value}}{SE}$$
    - *z* for proportions
    - *t* for means, along with appropriate degrees of freedom
  
---

## Hypothesis Tests Using the CLT 

- Use the test statistic to calculate the p-value, the probability of the observed outcome or a more extreme outcome given that the null hypothesis is true
    - Standard Normal distribution for proportions
    - *t* distribution with appropriate degrees of freedom for means (and eventually regression coefficients)

---

### *Sesame Street* Example using the CLT

- Sample Statistic, `\(\bar{x}_e - \bar{x}_{ne}\)`: 

```
## [1] 4.625
```


- Standard Error, `\(\sqrt{s_e^2/n_e + s_{ne}^2/n_{ne}}\)`: 


```
## [1] 1.49096
```


- Test Statistic, `\(\frac{(\bar{x}_e - \bar{x}_{ne} - 0)}{\sqrt{s_e^2/n_e + s_{ne}^2/n_{ne}}}\)`: 

```
## [1] 3.102028
```

- P-value: 

```
## [1] 0.001121931
```


---

### Theoretical distribution under `\(H_0\)`

*t* distribution with approximately 173.59 degrees of freedom. 

&lt;img src="02-review-ht_files/figure-html/unnamed-chunk-16-1.png" style="display: block; margin: auto;" /&gt;

---

class: middle, center 

### Understanding the Hypothesis Test

---

## Calculating the p-value

- &lt;font class="vocab3"&gt;p-value:&lt;/font&gt; probability of getting a test statistic as extreme or more extreme than the calculated test statistic, assuming the null hypothesis is true
--


- When the alternative has a `\(&gt;\)`, the p-value is calculated using the area to the right of the test statistic
--


- When the alternative has a `\(&lt;\)`, the p-value is calculated using the area to the left of the test statistic
--


- When the alternative has `\(\neq\)`, the p-value is calculated as the area to the left of `\(-|\text{test statistic}|\)` and to the right of `\(|\text{test statistic}|\)`

---

### Interpreting the p-value
--

**What the p-value is NOT**:
- It is &lt;u&gt;*not*&lt;/u&gt; the probability the null hypothesis is true
  + The null hypothesis is either true or not true
- (1 - *p-value*) is &lt;u&gt;*not*&lt;/u&gt; the probability that the alternative hypothesis is true
  + The alternative hypothesis is either true or not true

--

.alert[
Correct interpretation of the p-value: 

The probability of getting a test statistic as extreme or more extreme than the calculated test statistic, *assuming the null hypothesis is true.*
]

---

## Interpreting the p-value

|  Magnitude of p-value |             Interpretation            |
|:---------------------:|:-------------------------------------:|
| p-value &lt; 0.01        | strong evidence against `\(H_0\)`         |
| 0.01 &lt; p-value &lt; 0.05 | moderate evidence against `\(H_0\)`       |
| 0.05 &lt; p-value &lt; 0.1  | weak evidence against `\(H_0\)`           |
| p-value &gt; 0.1         | effectively no evidence against `\(H_0\)` |
&lt;br&gt; 
&lt;br&gt;

**Note:** These are general guidelines. The strength of evidence depends on the context of the problem.
---

## Statistical Significance

- A threshold can be used to decide whether or not to reject `\(H_0\)`. 

- This threshold is called the &lt;font class="vocab3"&gt;significance level&lt;/font&gt; and is usually denoted by `\(\alpha\)`

- When `\(H_0\)` is rejected, we use the term &lt;font class="vocab3"&gt; statistically significant &lt;/font&gt; to describe the outcome of the test.

- *Example*: When `\(\alpha = 0.05\)`, results are statistically significance when the p-value is `\(&lt; 0.05\)`

---

## Statistical Significance

- Do not rely strictly on the significance level to make a conclusion!
--

- Suppose the significance level is 0.05
--

  + If the p-value is 0.05001, we do not reject `\(H_0\)`
--

  + If the p-value is 0.04999, we do reject `\(H_0\)`
--

- 0.05001 and 0.04999 are practically the same, yet they led to different conclusions. 
--

- Always state the p-value when reporting results and assess it's magnitude in the context of your problem. 
---

class: results 

### Results that Aren't Statistically Significant

- An outcome of failing to reject `\(H_0\)` is &lt;u&gt;*not*&lt;/u&gt; a failed study/experiment

- Obtaining an outcome of "no significant effect" or "no significant difference" is still valid 

- It is often just as important to learn that the `\(H_0\)` can't be refuted

---

## Statistical Inference

- We concluded that there is a statistically significant difference in the average reading improvement between children who watched *Sesame Street* regularly compared to those who didn't

- From our sample data, the estimated difference is `\(\bar{x}_e - \bar{x}_{ne}\)` = 12.5 - 7.875 = 4.625

- Though this may be a good estimate, we saw earlier that there is variability in statistics calculated from sample data. 

- Next class, we will discuss how to account for that variability in our estimate of the parameter. 
---

## Before Next Class

- Fill out the **Getting To Know You Survey on Sakai** - due 9/2 at 11:59p

- Accept invite to join `sta210-fa19` organization on GitHub

- **New to R or need a refresher?**
  - Duke Libraries Rfun - Intro to R Workshop: Data Transformations, Data Structures, and the Tidyverse
      - September 12 1p - 3p
      - To register: https://duke.libcal.com/event/5497129
    - *Work with Data* primer on RStudio Cloud: [https://rstudio.cloud/learn/primers/2](https://rstudio.cloud/learn/primers/2)
    - "Data Visualization" in *R for Data Science*:
    [https://r4ds.had.co.nz/data-visualisation.html](https://r4ds.had.co.nz/data-visualisation.html)

- **More on statistical inference**
  - [OpenIntro Statistics](https://www.openintro.org/download.php?file=os3_tablet&amp;referrer=/stat/textbook.php) Chapter 5: Inference for numerical data
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"slideNumberFormat": "%current%"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
