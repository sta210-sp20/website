---
title: "Time Series"
author: "Dr. Maria Tackett"
date: "04.22.19"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: "sta210-slides.css"
    logo: img/sta210-sticker-icon.png
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE, echo=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
	fig.align = "center",
	fig.height = 4,
	fig.width = 7,
	message = FALSE,
	warning = FALSE
)
```


### Announcements


- Project write up due May 1 at 2p

- Project presentations on May 1
    - Lab 01L: 2p - 3:30p
    - Lab 02L: 3:30p - 5p

- Exam 2 extra credit: If the response rate for the course evaluations is 90%, everyone gets +1 pt on their Exam 2 score (out of 40 pts)

```{r,echo=F}
library(tidyverse)
library(cowplot)
library(tidyr)
library(knitr)
library(broom)
```

---

class: middle, center


## Examples of Time Series Data

---

## Gas Prices in Durham
 
.center[
```{r, echo=FALSE,out.width = '90%'}
knitr::include_graphics("img/23/durham-gas-price.png")
```

[https://www.gasbuddy.com/Charts](https://www.gasbuddy.com/Charts)
]

---

## Apple's Stock 

.center[
![](img/23/apple-stock.png)

[Apple's Stock Price](https://www.google.com/search?rlz=1C5CHFA_enUS812US814&tbm=fin&q=NASDAQ:+AAPL&stick=H4sIAAAAAAAAAONgecRoyi3w8sc9YSmdSWtOXmNU4-IKzsgvd80rySypFJLgYoOy-KR4uLj0c_UNzKtyk8rSeADviEaCOgAAAA&biw=1219&bih=1169#scso=_zp_YW7edDdGxggeTqLqYCw1:0)

]
---

class: middle, center

## Google Music Timeline

.center[
![](img/23/music-timeline.png)

[http://research.google.com/bigpicture/music/](http://research.google.com/bigpicture/music/)
]

---

class: center, middle 

## Today's Example 

---

## Bike rentals in DC

- <font class="vocab">Goal:</font> To predict the number of bike rentals in the Capital BikeShare. We'll use the 2012 data
<br>


```{r echo = F}
bike <- read_csv("data/bikeshare-day.csv") %>%
  filter(yr == 1) %>%
  mutate(temp_f = 41 * temp * 9/5 + 32, 
         temp_f_sq = temp_f^2)

ggplot(data = bike, aes(x = dteday, y = cnt)) +
  geom_line() + 
  labs(title = "Capital BikeShare Rentals", 
       subtitle = "in 2012", 
       x = "Date", 
       y = "Number of Rentals") +
  theme_minimal()
```

---

## Bike Rentals vs. Temperature

- In a previous analysis, we used temperature to predict number of bike rentals. 


```{r echo = F}
ggplot(data = bike, aes(x = temp_f, y = cnt)) +
  geom_point() + 
  labs(title = "Number of Rentals vs. Temperature", 
       subtitle = "in 2012", 
       x = "Temperature (in degress Fahrenheit)", 
       y = "Number of Rentals") +
  theme_minimal()
```
  
---

## Bike Rentals vs. Temperature

```{r echo = F}
model <- lm(cnt ~ temp_f + temp_f_sq, data = bike)
```

```{r echo = F}
kable(tidy(model), format = "html", digits = 3)

bike_aug <- augment(model) %>%
  mutate(dteday = bike$dteday)
ggplot(data = bike_aug, aes(x = dteday, y = .resid)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept = 0, color = "red") +
  labs(title = "Residuals over Time", 
       x = "Date", 
       y = "Residuals"
  )
```

There is evidence that the independence assumption is violated, i.e. there is **serial correlation**
---

## Time Series

- One assumption for the regression methods we've used so far is that the observations are independent of one another
    + In other words, the residuals are independent 
--

- When data is ordered over time, errors in one time period may influence error in another time period

--

- We'll use <font class = "vocab">time series analysis</font> to deal with this serial correlation
    + Assume the observations are measured at equally spaced time points

- Today's class is a brief introduction to time series analysis
  + You can take *STA 444: Statistical Modeling of Spatial and Time Series Data* for more in-depth study of the subject

---

## Autocorrelation

- We want a measure of the correlation between the observation at time $t$ and the observation at time $t-k$
    + $k$ is the **lag**

- To do so, we will compute the correlation between the observations (or  residuals) at time $t$ and time $t-k$
    - This is the **autocorrelation coefficient**

- The formula for the <font class="vocab">Lag <i>k</i> autocorrelation coefficient is </font>

$$r_k = \frac{\sum\limits_{i=1}^{n-k}(y_i - \bar{y})(y_{i+k} - \bar{y})}{\sum\limits_{i=1}^n (y_i - \bar{y})^2}$$

---

## Bikeshare rentals

```{r}
bike <- bike %>%
  mutate(cnt_lag_1 = lag(cnt, n = 1), 
         cnt_lag_2 = lag(cnt, n = 2))
```

```{r echo = F}
bike %>%
  select(cnt, cnt_lag_1, cnt_lag_2) %>%
  slice(1:5)
```

---

### Bikeshare: autocorrelation

- We can use the <font class="vocab">`acf()`</font> function to calculate the autocorrelation coefficient

```{r}
orig_acf <- acf(bike$cnt, plot = F)$acf
orig_acf[2] #lag 1 autocorrelation
```

---

## Autoregressive Model

- There are many models that can be used to account for serial correlation

- Common model is the <font class="vocab">autoregressive (AR) model</font>

- If we have no predictor variables, the AR model with one lag, the <font class="vocab3">AR(1) model</font>, is

$$y_t = \beta_0 + \beta_1 y_{t-1} + \epsilon_t \hspace{10mm} \epsilon_t \sim N(0,\sigma^2)$$

---

### Bikeshare: AR(1) Model 

```{r}
ar_1_model <- lm(cnt ~ cnt_lag_1, data = bike)
```

```{r echo = F}
kable(tidy(ar_1_model), format = "html", digits = 3)
```

--

- **Slope**: For each additional bike rental on day $t-1$, we expect there to be about 0.754 bike rentals on day $t$.

- **Intercept**: If there are 0 bike rentals on day $t-1$, we expect there to be about 1383 bike rentals on day $t$.
    - Not meaningful in practice

---

## Residual Plots

```{r}
ar_1_aug <- augment(ar_1_model) %>% 
  mutate(dteday = bike$dteday[2:nrow(bike)])
```

```{r echo = F}
ggplot(data = ar_1_aug, aes(x = .fitted, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0, color = "red") +
  labs(title = "Residuals vs. Predicted", 
       x = "Predicted", 
       y = "Residuals")
```

---

## Residual Plots

```{r echo = F}
ggplot(data = ar_1_aug, aes(x = dteday, y = .resid)) +
  geom_point() + 
  geom_line() + 
  geom_hline(yintercept = 0, color = "red") +
  labs(title = "Residuals vs. Date", 
       x = "Date", 
       y = "Residuals")
```

---

## Autocorrelation

- We can use the residuals to calculate autocorrelation to see if the AR(1) model is an appropriate fit for the data

```{r}
ar1_acf <- acf(ar_1_aug$.resid, plot = FALSE)$acf
ar1_acf[2] #lag 1 autocorrelation
```

- This is a significant improvement on the autocorrelation! But is there still significant autocorrelation? 

---

## ACF Plot 

- We can use an <font class = "vocab">autocorrelation function (ACF) plot</font> to see the autocorrelation at different lags 

- Generally, if the line extends outside of the blue dotted lines, there is  potentially significant autocorrelation between observations at time $t$ and time $t-k$

```{r}
acf(ar_1_aug$.resid, plot = TRUE, main = "ACF of Residuals after AR(1) Model")
```

---

## ACF Plot 

```{r}
acf(ar_1_aug$.resid, plot = TRUE, main = "ACF of Residuals after AR(1) Model")$acf[2]
```

- Autocorrelation is much lower, but can we reduce it further?

---

### Try AR(2) Model

```{r}
ar_2_model <- lm(cnt ~ cnt_lag_1 + cnt_lag_2, data = bike[-2,])
kable(tidy(ar_2_model), format = "html", digits = 3)
```

---

## ACF Plot

```{r echo = F}
ar_2_aug <- augment(ar_2_model)
acf(ar_2_aug$.resid, main = "ACF of Residuals After AR(2) Model")$acf[2]
```

This autocorrelation looks good!

---

## Add Predictors 

Go to **Time Series** project on RStudio Cloud






