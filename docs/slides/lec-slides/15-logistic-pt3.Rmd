---
title: "Logistic regression"
subtitle: "Inference & Model selection"
author: "Prof. Maria Tackett"
date: "04.01.20"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: "sta210-slides.css"
    logo: img/sta210-sticker-icon.png
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: "%current%"
---

```{r setup, include=FALSE, echo=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
	fig.align = "center",
	fig.height = 4,
	fig.width = 7,
	message = FALSE,
	warning = FALSE
)
```

class: middle, center

### [Click for PDF of slides](15-logistic-pt3.pdf)

```{r,echo=F}
library(tidyverse)
library(knitr)
library(broom)
library(pROC) #ROC curves
```

---

### Risk of coronary heart disease 

This dataset is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. We want to predict if a patient has a high risk of getting coronary heart disease in the next 10 years. 

**Response**: 

.vocab[`TenYearCHD`]: 
- 0 = Patient is not high risk of having coronary heart disease in the next 10 years 
- 1 = Patient is high risk of having coronary heart disease in the next 10 years 

**Predictors**: 

- .vocab[`age`]: Age at exam time.
- .vocab[`currentSmoker`]: 0 = nonsmoker; 1 = smoker
- .vocab[`totChol`]: total cholesterol (mg/dL)


```{r echo = F}
heart_data <- read_csv("data/framingham.csv") %>%
  drop_na() %>%
  mutate(currentSmoker = as.factor(currentSmoker), 
         TenYearCHD = as.factor(TenYearCHD), 
         ageCent = age - mean(age), 
         totCholCent = totChol - mean(totChol), 
         education = as.factor(education))
```

---

### Modeling risk of coronary heart disease

```{r echo = F}
risk_m <- glm(TenYearCHD ~ ageCent + currentSmoker + totCholCent, data = heart_data, 
         family = binomial)
tidy(risk_m, conf.int = TRUE) %>% kable(format = "markdown", digits = 3)
```

---

### Hypothesis test for $\beta_j$

$$\log\Big(\frac{\hat{\pi}}{1-\hat{\pi}}\Big) = \hat{\beta}_0 + \hat{\beta}_1 x_{1} + \hat{\beta}_2 x_{2} + \dots + \hat{\beta}_p x_{p}$$

The test of significance for the coefficient $\beta_j$ is 

.alert[

**Hypotheses**: $H_0: \beta_j = 0 \hspace{2mm} \text{ vs } \hspace{2mm} H_a: \beta_j \neq 0$

**Test Statistic**: $$z = \frac{\hat{\beta}_j - 0}{SE(\hat{\beta_j})}$$

**P-value**: $P(|Z| > |z|)$, 

where $Z \sim N(0, 1)$, the Standard Normal distribution
]

---

### Confidence interval for $\beta_j$

- We can calculate the .vocab[C\% confidence interval] for $\beta_j$ using the following:

$$\hat{\beta}_j \pm z^* SE(\hat{\beta}_j)$$
where $z^*$ is calculated from the $N(0,1)$ distribution

.alert[
We are $C\%$ confident that for every one unit change in $x_j$, the odds multiply by a factor of $\exp\{\hat{\beta}_j - z^* SE(\hat{\beta}_j)\}$ to $\exp\{\hat{\beta}_j + z^* SE(\hat{\beta}_j)\}$, holding all else constant.
  ]

---

### Modeling risk of coronary heart disease

```{r echo = F}
risk_m <- glm(TenYearCHD ~ ageCent + currentSmoker + totCholCent, data = heart_data, 
         family = binomial)
tidy(risk_m, conf.int = TRUE) %>% kable(format = "markdown", digits = 5)
```

.question[
1. How is the test statistic for `currentSmoker1` calculated? 
2. Is `totCholCent` a statistically significant predictor of the odds a person is high risk for coronary heart disease? 
  - Justify your answer using the test statistic and p-value.
  - Justify your answer using the confidence interval. 
]

---

class: middle, center

### Model Selection 
---

### Comparing Nested Models 

- Suppose there are two models: 
    - Reduced Model includes predictors $x_1, \ldots, x_q$
    - Full Model includes predictors $x_1, \ldots, x_q, x_{q+1}, \ldots, x_p$

- We want to test the hypotheses
$$\begin{aligned}&H_0: \beta_{q+1} = \dots = \beta_p = 0 \\
& H_a: \text{ at least 1 }\beta_j \text{ is not} 0\end{aligned}$$

- To do so, we will use the .vocab[Drop-in-Deviance test] (also known as the Nested Likelihood test) 

---

### Deviance residual 

- The .vocab[deviance residual] is the a measure of how much the observed data differs from what is measured using the likelihood ratio 

- The deviance residual for the $i^{th}$ observation is 

.alert[
$$d_i = \text{sign}(y_i - \hat{\pi}_i)\sqrt{2\bigg[y_i \log\Big(\frac{y_i}{\hat{\pi}_i}\Big) + (1-y_i)\log\Big(\frac{1-y_i}{1-\hat{\pi}_i}\Big)\bigg]}$$
where $\text{sign}(y_i - \hat{\pi}_i)$ is positive when $y_i = 1$ and negative when $y_i = 0$.
]

---

### Drop-in-Deviance Test

- The .vocab[deviance statistic for Model *k*] is $G^2_k = \sum\limits_{i=1}^n d_i^2$

--

- To test the hypotheses
$$\begin{aligned}&H_0: \beta_{q+1} = \dots = \beta_p = 0 \\
& H_a: \text{ at least one }\beta_j \text{ is not} 0\end{aligned}$$

--

the <font class="vocab"> drop-in-deviance statistic </font> is $G^2_{reduced}- G^2_{full}$

--

The p-value for the test is calculated using a Chi-square distribution $(\chi^2)$ with degrees of freedm equal to the difference in the number of parameters in the full and reduced models

---

### $\chi^2$ distribution 

```{r, echo=F, fig.height = 5}
x <- seq(from =0, to = 10, length = 100)

# Evaluate the densities
y_1 <- dchisq(x, 1)
y_2 <- dchisq(x,2)
y_3 <- dchisq(x,3)
y_4 <- dchisq(x,5)

# Plot the densities
plot(x, y_1, col = 1, type = "l", ylab="",lwd=3, ylim = c(0, 0.5), 
     main  = "Chi-square Distribution")
lines(x,y_2, col = 2,lwd=3)
lines(x, y_3, col = 3,lwd=3)
lines(x, y_4, col = 4,lwd=3)

# Add the legend
legend("topright",
       c("df = 1", "df = 2 ", "df = 3", "df = 5"), 
       col = c(1, 2, 3, 4), lty = 1)
```

<br>

Calculate p-value for the drop-in-deviance test as $P(\chi^2 > \text{test statistic})$
---

### Should we add `education` to the model?

.small[
```{r}
model_red <- glm(TenYearCHD ~ ageCent + currentSmoker + totChol, 
              data = heart_data, family = binomial)
model_full <- glm(TenYearCHD ~ ageCent + currentSmoker + totChol + 
               education, 
              data = heart_data, family = binomial)
```
]

```{r echo = F}
tidy(model_full, conf.int = T) %>% kable(format = "markdown", digits = 3)
```

---

### Should we add `education` to the model?

```{r}
# Deviances
(dev_red <- glance(model_red)$deviance)
```

--

```{r}
(dev_full <- glance(model_full)$deviance)
```

--

```{r}
# Drop-in-deviance test statistic
(test_stat <- dev_red - dev_full)
```

---

### Should we add `education` to the model?

```{r}
# p-value
1 - pchisq(test_stat, 3) #3 = number of new model terms in model2
```


.question[
What is your conclusion for the test?
]

---

### Drop-in-Deviance test in R

- We can use the **`anova`** function to conduct this test 
    - Add **`test = "Chisq"`** to conduct the drop-in-deviance test

```{r}
anova(model_red, model_full, test = "Chisq")
```

---

### Model selection 

- Use AIC or BIC for model selection 

.alert[
$$AIC = - 2 * L - \color{red}{n\log(n)}+ 2(p +1)$$
$$BIC =- 2 * L - \color{red}{n\log(n)} + log(n)\times(p+1)$$

where $L = \sum\limits_{i=1}^n[y_i \log(\hat{\pi}_i) + (1 - y_i)\log(1 - \hat{\pi}_i)]$
]
---

### AIC from `glance` function

Let's look at the AIC for the model that includes `ageCent`, `currentSmoker`, and `totCholCent`
```{r}
glance(model_red)$AIC
```

--

**Calculating AIC**

```{r}
(L <- glance(model_red)$logLik)
```

```{r}
- 2 * L + 2 * (3 + 1)
```

---

### Should we add education to the model? 

**Recall:**
- Reduced Model includes `AgeCent`, `currentSmoker`, `totCholCent`
- Full Model includes `AgeCent`, `currentSmoker`, `totCholCent`, `education` (categorical)

```{r}
glance(model_red)$AIC
glance(model_full)$AIC
```

.question[
Based on the AIC, which model would you choose?
]


---

class: middle, center

### What remaining questions do you have about logistic regression?




